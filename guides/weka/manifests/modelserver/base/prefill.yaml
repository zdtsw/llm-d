apiVersion: apps/v1
kind: Deployment
metadata:
  name: prefill
spec:
  replicas: 4
  selector:
    matchLabels:
      llm-d.ai/role: prefill
  template:
    metadata:
      labels:
        llm-d.ai/role: prefill
    spec:
      initContainers:
        - name: create-cufile-on-node
          # TODO: replace this with a simple image
          image: quay.io/grpereir/amg-utils:latest
          command:
            - /usr/local/bin/entrypoint.sh # Generate cufile.json
          args:
            - /bin/bash
            - -lc
            - true
      serviceAccountName: llama-3-3-70b-instruct-fp8-dynamic
      volumes:
        - name: weka-storage # value patched in overlays
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
        - name: host-node-cufile
          hostPath:
            path: ~/amg_stable/cufile.json
            type: File
      containers:
        - name: vllm
          image: ghcr.io/llm-d/llm-d:latest
          command: ["vllm", "serve"]
          args:
            - RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic
            - --port
            - "8000"
            - --served-model-name
            - "RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic"
            - --block-size
            - "128"
            - --kv-transfer-config
            - '{"kv_connector":"NixlConnector", "kv_role":"kv_both"}'
            - --disable-log-requests
            - --disable-uvicorn-access-log
            - --max-model-len
            - "32000"
          env:
            - name: VLLM_NIXL_SIDE_CHANNEL_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            # DEBUG IF NEEDED
            - name: VLLM_LOGGING_LEVEL
              value: INFO
            - name: NCCL_DEBUG
              value: "INFO"
            # LOAD MODEL FROM WEKA MOUNT POINT
            - name: HF_HOME
              value: "/mnt/weka/hf_cache"
            - name: NCCL_SOCKET_IFNAME
              value: "=enp157s0np0,enp158s0np0"
            - name: NCCL_IB_HCA
              value: "ibp"
            - name: UCX_NET_DEVICES
              value: "ibp0:1,ibp1:1,ibp2:1,ibp3:1,ibp4:1,ibp5:1,ibp6:1,ibp7:1"
            - name: NVIDIA_GDRCOPY
              value: "enabled"
          ports:
            - containerPort: 8000
              name: metrics
              protocol: TCP
          resources:
            limits:
              cpu: "8"
              memory: 64Gi
              nvidia.com/gpu: "1"
              rdma/ib: 1
            requests:
              cpu: "8"
              memory: 64Gi
              nvidia.com/gpu: "1"
              rdma/ib: 1
          startupProbe:
            exec:
              command:
                - "/usr/local/bin/gds-cufile-probe.sh"
            initialDelaySeconds: 5
            periodSeconds: 5
            failureThreshold: 12
          readinessProbe:
            httpGet:
              path: /v1/models
              port: 8000
            periodSeconds: 5
            timeoutSeconds: 2
            failureThreshold: 3
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          volumeMounts:
            - name: shm
              mountPath: /dev/shm
            - name: weka-storage
              mountPath: /mnt/weka
            - name: host-node-cufile
              mountPath: /etc/cufile.json
              readOnly: true
