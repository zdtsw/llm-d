apiVersion: apps/v1
kind: Deployment
metadata:
  name: decode
  labels:
spec:
  replicas: 1
  selector:
    matchLabels:
      llm-d.ai/role: decode
  template:
    metadata:
      labels:
        llm-d.ai/role: decode
    spec:
      initContainers:
        - name: routing-proxy
          args:
            - --port=8000
            - --vllm-port=8200
            - --connector=nixlv2
            - -v=1
            - --secure-proxy=false
          image: ghcr.io/llm-d/llm-d-routing-sidecar:v0.4.0
          imagePullPolicy: Always
          ports:
            - containerPort: 8000
          resources: {}
          restartPolicy: Always
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
        - name: create-cufile-on-node
          # TODO: replace this with a simple image
          image: quay.io/grpereir/amg-utils:latest
          command:
            - /usr/local/bin/entrypoint.sh  # Generate cufile.json
          args:
            - /bin/bash
            - -lc
            - true
      serviceAccountName: llama-3-3-70b-instruct-fp8-dynamic
      volumes:
        - name: weka-storage # value patched in overlays
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
        - name: host-node-cufile
          hostPath:
            path: ~/amg_stable/cufile.json
            type: File
      containers:
        - name: vllm
          image: ghcr.io/llm-d/llm-d:latest
          command: ["vllm", "serve"]
          args:
            - RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic
            - --port
            - "8200"
            - --served-model-name
            - "RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic"
            - --tensor-parallel-size
            - "4"
            - --block-size
            - "128"
            - --kv-transfer-config
            - '{"kv_connector":"NixlConnector", "kv_role":"kv_both"}'
            - --disable-log-requests
            - --disable-uvicorn-access-log
            - --max-model-len
            - "32000"
          env:
            - name: VLLM_NIXL_SIDE_CHANNEL_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            # DEBUG IF NEEDED
            - name: VLLM_LOGGING_LEVEL
              value: INFO
            - name: NCCL_DEBUG
              value: "INFO"
            # LOAD MODEL FROM WEKA MOUNT POINT, Kustomization overlay
            - name: HF_HOME
              value: "/mnt/weka/hf_cache"
            - name: NCCL_SOCKET_IFNAME
              value: "=enp157s0np0,enp158s0np0"
            - name: NCCL_IB_HCA
              value: "ibp"
            - name: UCX_NET_DEVICES
              value: "ibp0:1,ibp1:1,ibp2:1,ibp3:1,ibp4:1,ibp5:1,ibp6:1,ibp7:1"
            - name: NVIDIA_GDRCOPY
              value: "enabled"
          ports:
            - containerPort: 8200
              name: metrics
              protocol: TCP
          resources:
            limits:
              cpu: "16"
              memory: 64Gi
              nvidia.com/gpu: "4"
              rdma/ib: 1
            requests:
              cpu: "16"
              memory: 64Gi
              nvidia.com/gpu: "4"
              rdma/ib: 1
          startupProbe:
            exec:
              command:
                - "/usr/local/bin/gds-cufile-probe.sh"
            initialDelaySeconds: 5
            periodSeconds: 5
            failureThreshold: 12
          readinessProbe:
            httpGet:
              path: /v1/models
              port: 8200
            periodSeconds: 5
            timeoutSeconds: 2
            failureThreshold: 3
          livenessProbe:
            httpGet:
              path: /health
              port: 8200
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          volumeMounts:
            - name: shm
              mountPath: /dev/shm
            - name: weka-storage
              mountPath: /mnt/weka
            - name: host-node-cufile
              mountPath: /etc/cufile.json
              readOnly: true
