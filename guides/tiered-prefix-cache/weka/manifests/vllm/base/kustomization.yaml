apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ../../../../../recipes/vllm/standard

labels:
  - pairs:
      llm-d.ai/inferenceServing: "true"
      llm-d.ai/model: Llama-33-70B-Instruct

patches:
  # Update image to latest llm-d
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: replace
        path: /spec/template/spec/containers/0/image
        value: "ghcr.io/llm-d/llm-d:latest"

  # Update command and args for WEKA deployment
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: replace
        path: /spec/template/spec/containers/0/command
        value:
          - "vllm"
          - "serve"
      - op: replace
        path: /spec/template/spec/containers/0/args
        value:
          - "RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic"
          - "--port"
          - "8000"
          - "--served-model-name"
          - "RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic"
          - "--block-size"
          - "128"
          - "--kv-transfer-config"
          - '{"kv_connector":"MultiConnector","kv_role":"kv_both","kv_connector_extra_config":{"connectors":[{"kv_connector":"NixlConnector","kv_role":"kv_both"},{"kv_connector":"LMCacheConnectorV1","kv_role":"kv_both"}]}}'
          - "--disable-log-requests"
          - "--disable-uvicorn-access-log"
          - "--max-model-len"
          - "32000"

  # Remove HF_TOKEN from base recipe (not needed for WEKA deployment)
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: remove
        path: /spec/template/spec/containers/0/env/0

  # Add vLLM environment variables
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: add
        path: /spec/template/spec/containers/0/env/-
        value:
          name: VLLM_NIXL_SIDE_CHANNEL_HOST
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
      - op: add
        path: /spec/template/spec/containers/0/env/-
        value:
          name: VLLM_LOGGING_LEVEL
          value: "INFO"
      - op: add
        path: /spec/template/spec/containers/0/env/-
        value:
          name: NCCL_DEBUG
          value: "INFO"
      - op: add
        path: /spec/template/spec/containers/0/env/-
        value:
          name: HF_HOME
          value: "/mnt/weka/hf_cache"
      - op: add
        path: /spec/template/spec/containers/0/env/-
        value:
          name: NCCL_SOCKET_IFNAME
          value: "=enp157s0np0,enp158s0np0"
      - op: add
        path: /spec/template/spec/containers/0/env/-
        value:
          name: NCCL_IB_HCA
          value: "ibp"
      - op: add
        path: /spec/template/spec/containers/0/env/-
        value:
          name: UCX_NET_DEVICES
          value: "ibp0:1,ibp1:1,ibp2:1,ibp3:1,ibp4:1,ibp5:1,ibp6:1,ibp7:1"
      - op: add
        path: /spec/template/spec/containers/0/env/-
        value:
          name: NVIDIA_GDRCOPY
          value: "enabled"

  # Update resources for WEKA deployment
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: replace
        path: /spec/template/spec/containers/0/resources
        value:
          limits:
            cpu: "8"
            memory: 64Gi
            nvidia.com/gpu: "1"
            rdma/ib: 1
          requests:
            cpu: "8"
            memory: 64Gi
            nvidia.com/gpu: "1"
            rdma/ib: 1

  # Add initContainers for WEKA GDS setup
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: add
        path: /spec/template/spec/initContainers
        value:
          - name: enable-nvidia-gds
            image: "ghcr.io/llm-d/llm-d:latest"
            command:
              - /usr/local/bin/enable-nvidia-gds.sh
            securityContext:
              privileged: true
          - name: create-cufile-on-node
            image: quay.io/grpereir/amg-utils:latest
            command:
              - /usr/local/bin/entrypoint.sh
            args:
              - /bin/bash
              - -lc
              - "true"

  # Replace startup probe with GDS-specific probe
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: replace
        path: /spec/template/spec/containers/0/startupProbe
        value:
          exec:
            command:
              - "/usr/local/bin/gds-startup-probe.sh"
          initialDelaySeconds: 5
          periodSeconds: 5
          failureThreshold: 12

  # Update readiness probe
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: replace
        path: /spec/template/spec/containers/0/readinessProbe
        value:
          httpGet:
            path: /v1/models
            port: 8000
          periodSeconds: 5
          timeoutSeconds: 2
          failureThreshold: 3

  # Update liveness probe
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: replace
        path: /spec/template/spec/containers/0/livenessProbe
        value:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3

  # Update service account
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: add
        path: /spec/template/spec/serviceAccountName
        value: weka-vllm

  # Remove data volume from base (not needed for WEKA)
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: remove
        path: /spec/template/spec/volumes/0

  # Update shm volume to add sizeLimit
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: replace
        path: /spec/template/spec/volumes/0
        value:
          name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi

  # Add WEKA storage volumes (will be patched by storage overlays)
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: add
        path: /spec/template/spec/volumes/-
        value:
          name: weka-storage
          # This will be patched by storage overlays (pvc or hostPath)
      - op: add
        path: /spec/template/spec/volumes/-
        value:
          name: host-node-cufile
          hostPath:
            path: ~/amg_stable/cufile.json
            type: File

  # Remove data volumeMount from base (not needed for WEKA)
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: remove
        path: /spec/template/spec/containers/0/volumeMounts/0

  # Add WEKA storage volume mounts
  - target:
      kind: Deployment
      name: llm-d-model-server
    patch: |-
      - op: add
        path: /spec/template/spec/containers/0/volumeMounts/-
        value:
          name: weka-storage
          mountPath: /mnt/weka
      - op: add
        path: /spec/template/spec/containers/0/volumeMounts/-
        value:
          name: host-node-cufile
          mountPath: /etc/cufile.json
          readOnly: true
