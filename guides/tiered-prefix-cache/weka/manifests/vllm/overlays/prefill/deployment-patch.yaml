apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-d-model-server
spec:
  replicas: 4
  selector:
    matchLabels:
      llm-d.ai/role: prefill
  template:
    metadata:
      labels:
        llm-d.ai/role: prefill
    spec:
      serviceAccountName: weka-vllm
      containers:
        - name: vllm
          args:
            - RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic
            - --port
            - "8000"
            - --served-model-name
            - RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic
            - --block-size
            - "128"
            - --kv-transfer-config
            - '{"kv_connector":"NixlConnector", "kv_role":"kv_both"}'
            - --disable-log-requests
            - --disable-uvicorn-access-log
            - --max-model-len
            - "32000"
