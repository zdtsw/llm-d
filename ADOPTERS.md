> **Note**
> Do you want to add yourself to this list? Simply fork the repository and open a PR with the required change.

# llm-d Adopters

| Type | Name | Since | Website | Description |
| :- | :- | :- | :- | :- |
| Founding Contributor | CoreWeave | 2025 | [CoreWeave](https://www.coreweave.com) | CoreWeave is a founding contributor to llm-d, building on their long-standing commitment to open source AI and scalable inference infrastructure. |
| Founding Contributor | Google Cloud | 2025 | [Google Cloud](https://cloud.google.com) | Google Cloud is a founding contributor to llm-d, contributing to distributed AI inference at scale and support for Google Cloud TPUs in vLLM. |
| Founding Contributor | IBM Research | 2025 | [IBM Research](https://research.ibm.com) | IBM Research is a founding contributor to llm-d, focused on building a hardware-agnostic distributed AI inference platform for enterprise workloads. |
| Founding Contributor | NVIDIA | 2025 | [NVIDIA](https://www.nvidia.com) | NVIDIA is a founding contributor to llm-d, accelerating the project with innovations from NVIDIA Dynamo including the NVIDIA Inference Xfer Library (NIXL). |
| Founding Contributor | Red Hat | 2025 | [Red Hat](https://www.redhat.com) | Red Hat is a founding contributor to llm-d, providing project infrastructure and community stewardship in collaboration with the broader contributor community. |
| Launch Partner | AMD | 2025 | [AMD](https://www.amd.com) | AMD contributes high-performance GPU expertise to advance AI inference for evolving enterprise AI needs. |
| Launch Partner | Cisco | 2025 | [Cisco](https://www.cisco.com) | Cisco is exploring real-world use cases that help organizations apply AI more effectively and efficiently through llm-d. |
| Launch Partner | Hugging Face | 2025 | [Hugging Face](https://huggingface.co) | Hugging Face supports llm-d to help developers take AI applications built on the Hugging Face ecosystem to scale. |
| Launch Partner | Intel | 2025 | [Intel](https://www.intel.com) | Intel is a launch partner supporting llm-d as the latest milestone in a decades-long collaboration with Red Hat to empower enterprises with open source solutions. |
| Launch Partner | Lambda | 2025 | [Lambda](https://lambdalabs.com) | Lambda supports llm-d to make state-of-the-art inference accessible, efficient, and open. |
| Launch Partner | Mistral AI | 2025 | [Mistral AI](https://mistral.ai) | Mistral AI is a launch partner supporting the llm-d community for distributed generative AI inference at scale. |
| Contributor | DaoCloud | 2025 | [DaoCloud](https://www.daocloud.io) | DaoCloud contributes to llm-d, leveraging P/D disaggregation and KV-cache architectures in its d.run MaaS platform. |
| University Supporter | University of California, Berkeley (Sky Computing Lab) | 2025 | [Sky Computing Lab](https://sky.cs.berkeley.edu) | The Sky Computing Lab at UC Berkeley, originators of vLLM, are founding academic supporters of llm-d. |
| University Supporter | University of Chicago (LMCache Lab) | 2025 | [LMCache Lab](https://lmcache.ai) | The LMCache Lab at the University of Chicago, originators of LMCache, are founding academic supporters of llm-d. |
| User | Tesla | 2025 | [Tesla](https://www.tesla.com/) | The Tesla ML Platform team are users of llm-d. |

## Adopter Types

**Founding Contributor**: The organization is a founding contributor to the llm-d project, actively contributing from the project's inception.

**Launch Partner**: The organization is a supporting partner at the launch of the llm-d project, contributing expertise and collaboration to the community.

**Contributor**: The organization actively contributes code, documentation, or community resources to the llm-d project.

**University Supporter**: An academic institution supporting the llm-d project, often through originating or contributing to foundational open source technologies used by llm-d.

**User**: The organization is a user of the llm-d project, contributing feedback and real-world examples to the community.
